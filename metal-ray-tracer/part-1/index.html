<meta charset="utf-8">
**Metal ray-tracer: tracing our first triangle**

In this post I will describe the basics of using Metal Performance Shaders.
We will set-up a project and execute some compute shaders on GPU. And then we are going to trace one hard-coded triangle.

[Source Code](http://github.com/sergeyreznik/metal-ray-tracer/tree/part-1)
for this post is available on my GitHub page.

Setting up an environment
================================================================================
We will start from creating Game template in Xcode.
Be sure to select **Objective-C** as language and **Metal** as game technology:

![](images/pic-1.png)

If everything goes well - you will be able to compile and run an application and see a colored spinning cube.
After that we will remove redundant parts of the demo.
For now, we just want to see a black screen, using minimal source code.
Also, don't forget to rename **.m** files to **.mm** to be able to use C++ in the code.

After cleaning up the code to only acquire and present current drawable,
your `- (void)drawInMTKView:(nonnull MTKView *)view` should look like this:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
- (void)drawInMTKView:(nonnull MTKView *)view
{
    dispatch_semaphore_wait(_frameSemaphore, DISPATCH_TIME_FOREVER);
    id<MTLCommandBuffer> commandBuffer = [_commandQueue commandBuffer];

    __block dispatch_semaphore_t block_sema = _frameSemaphore;
    [commandBuffer addCompletedHandler:^(id<MTLCommandBuffer> buffer) {
        dispatch_semaphore_signal(block_sema);
    }];

    [commandBuffer presentDrawable:view.currentDrawable];
    [commandBuffer commit];
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
And it should output some garbage to the screen (solid red color in my case), because we are not doing anything like
clear or draw to the drawable's texture.

Adding and testing Metal compute shaders
================================================================================

Let's start with a simple compute shader, which will fill a texture with a default red/green pattern based on texture coordinates.
We will be using [Default Library](https://developer.apple.com/documentation/metal/mtldevice/1433380-newdefaultlibrary?language=objc)
so, all our `*.metal` files in the Xcode project will be compiled and could be easily accessed.

Please take a look at [Metal Shading Language Specification](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf)
if you have never done this before.

The simplest compute shader for filling image with UV coordinates should look like:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Obj-C
kernel void imageFillTest(
    texture2d<float, access::write> image [[texture(0)]],
    uint2 coordinates [[thread_position_in_grid]],
    uint2 size [[threads_per_grid]])
{
    float2 uv = float2(coordinates) / float2(size - 1);
    image.write(float4(uv, 0.0, 1.0), coordinates);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
Where `threads_per_grid` attribute specifies the dimension of the excution grid and `thread_position_in_grid` attribute
specifies currently executed thread position in the execution grid.

See section **4.3.4.6 Kernel Function Input Attributes** in Metal SL specs for details.

Also we need to create a writable texture that we can use as compute shader output, so let's just make it **RGBA32F**.
Since we want to handle window size changes, let's create (or re-create texture) on window resize. So the best place to do this
would be `drawableSizeWillChange` method:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
- (void)mtkView:(nonnull MTKView *)view drawableSizeWillChange:(CGSize)size
{
    _outputImageSize.width = size.width;
    _outputImageSize.height = size.height;
    _outputImageSize.depth = 1.0f;

    MTLTextureDescriptor* outputImageDescriptor = [MTLTextureDescriptor new];
    outputImageDescriptor.pixelFormat = MTLPixelFormatRGBA32Float;
    outputImageDescriptor.width = NSUInteger(size.width);
    outputImageDescriptor.height = NSUInteger(size.height);
    outputImageDescriptor.usage |= MTLTextureUsageShaderWrite;
    outputImageDescriptor.storageMode = MTLStorageModePrivate;

    _outputImage = [_device newTextureWithDescriptor:outputImageDescriptor];
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
Since we are going to use this texture only on GPU we will specify `storageMode` as `MTLStorageModePrivate`.
And we need to add `MTLTextureUsageShaderWrite` to the texture's usage to be able to write data into it in the compute shader.

Now let's create a `MTLComputePipelineState` object and initialize it with our `imageFillTest` function. For this I've created helper method
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
- (id<MTLComputePipelineState>)newComputePipelineWithFunctionName:
    (NSString*)functionName
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
Which loads a `MTLFunction` with specified name from the default library and creates `MTLComputePipelineState` object. See its implementation in the source code.

Another useful utility method would be the one which actually dispatches specified compute shader:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
-(void)dispatchComputeShader:(id<MTLComputePipelineState>)pipelineState
    withinCommandBuffer:(id<MTLCommandBuffer>)commandBuffer
    setupBlock:(void(^)(id<MTLComputeCommandEncoder>))setupBlock
{
    id<MTLComputeCommandEncoder> commandEncoder =
        [commandBuffer computeCommandEncoder];

    setupBlock(commandEncoder);

    [commandEncoder setComputePipelineState:_testComputeShader];
    [commandEncoder dispatchThreads:_outputImageSize
    threadsPerThreadgroup:MTLSizeMake(8, 8, 1)];
    [commandEncoder endEncoding];
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

So now we are ready to dispatch our test compute shader, that fills output texture. But we won't see any result on the screen.
Therefore we need to add a render pipeline, which will basically blit the output texture to the drawable's texture so we can see it.
Let's create a simple vertex and fragment shaders and draw a full screen triangle, it will just copy our float texture to the screen.
Later this shader could be extended to do tone mapping, comparison with reference images, etc., but for now, blit shaders will be very simple:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
struct BlitVertexOut
{
    float4 pos [[position]];
    float2 coords;
};

constant constexpr static const float4 fullscreenTrianglePositions[3]
{
    {-1.0, -1.0, 0.0, 1.0},
    { 3.0, -1.0, 0.0, 1.0},
    {-1.0,  3.0, 0.0, 1.0}
};

vertex BlitVertexOut blitVertex(uint vertexIndex [[vertex_id]])
{
    BlitVertexOut out;
    out.pos = fullscreenTrianglePositions[vertexIndex];
    out.coords = out.pos.xy * 0.5 + 0.5;
    return out;
}

fragment float4 blitFragment(BlitVertexOut in [[stage_in]],
    texture2d<float> image [[texture(0)]])
{
    constexpr sampler linearSampler(coord::normalized, filter::nearest);
    float4 color = image.sample(linearSampler, in.coords);
    return color;
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

If everything goes well (and I really hope it is), we will see our texture, filled in our compute shader:
![](images/pic-2.png)

Adding ray-tracing Metal Performance Shaders
================================================================================

Now let's add ray-tracing Metal Performance Shaders. For now we will be need only two objects:
- `MPSTriangleAccelerationStructure`
- `MPSRayIntersector`

Apple's [documentation](https://developer.apple.com/documentation/metalperformanceshaders/mpstriangleaccelerationstructure?language=objc) is being
very laconic about it and says only:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ DISABLED
An acceleration structure built over triangles.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Nevertheless, this is very true :)

`MPSRayIntersector` is basically an object which actually does ray-geometry intersection using an acceleration structure.
Basically it sets up and dispatches compute shader for that.

Both of them requires only `MTLDevice` upon the creation. Therefore adding ray-tracing Metal Performance Shaders means to create a method:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
-(void)initializeRayTracing
{
    _accelerationStructure =
        [[MPSTriangleAccelerationStructure alloc] initWithDevice:_device];

    _rayIntersector =
        [[MPSRayIntersector alloc] initWithDevice:_device];
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Tracing one hard-coded triangle
================================================================================
Seems like we get into the most interesting part of the post. Let's hard-code and trace a single triangle.
As soon as we will be able to trace a single triangle things will be much clearer and the rest of ray-tracer will be
much easier to understand and implement. So, for tracing one triangle we will be need to:
- create vertex and index buffers for triangle;
- build an acceleration structure;
- create buffers for ray and intersection structures;
- generate rays using compute shader;
- dispatch intersection shader;
- process intersection results and update the output image;

Creating vertex and index buffer for triangle is very straightfoward, we will just declare three sequential
vertices and create buffers for them:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
struct Vertex { float x, y, z, w; } vertices[3] = {
    { 0.25f, 0.25f, 0.0f },
    { 0.75f, 0.25f, 0.0f },
    { 0.50f, 0.75f, 0.0f }
};
id<MTLBuffer> vertexBuffer = [_device newBufferWithBytes:vertices
    length:sizeof(vertices) options:MTLResourceStorageModeManaged];

uint32_t indices[3] = { 0, 1, 2 };
id<MTLBuffer> indexBuffer = [_device newBufferWithBytes:indices
    length:sizeof(indices) options:MTLResourceStorageModeManaged];
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Now let'sbuild an acceleration structure using our vertex and index buffers containing the single triangle.
To make that we just need to setup buffers, their contents size and number of triangles, and just call `rebuild` method:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
[_accelerationStructure setVertexBuffer:vertexBuffer];
[_accelerationStructure setVertexStride:sizeof(Vertex)];
[_accelerationStructure setIndexBuffer:indexBuffer];
[_accelerationStructure setIndexType:MPSDataTypeUInt32];
[_accelerationStructure setTriangleCount:1];
[_accelerationStructure rebuild];
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Also we need to setup a ray intersector. It needs to know type of ray and intersection structures and their actual sizes
(specified as `stride`) - this can be used to extend structures with user data.
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
[_rayIntersector setRayStride:sizeof(Ray)];
[_rayIntersector setRayDataType:
    MPSRayDataTypeOriginMinDistanceDirectionMaxDistance];

[_rayIntersector setIntersectionStride:sizeof(Intersection)];
[_rayIntersector setIntersectionDataType:
    MPSIntersectionDataTypeDistancePrimitiveIndexCoordinates];
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

We will declare the structures `Ray` and `Intersection` in the separate header file, which can be included from Objective-C
code as well as from Metal code. For now, we don't need to include any extra data to our structures, so we can just use
built-in types:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Obj-C
#include <MetalPerformanceShaders/MetalPerformanceShaders.h>

using Ray = MPSRayOriginMinDistanceDirectionMaxDistance;
using Intersection = MPSIntersectionDistancePrimitiveIndexCoordinates;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
Later we will extend `Ray` structure at least with throughput and radiance values.

Also we need to allocate a buffers on the GPU for rays and interesctions. The amount of memory for these buffers would be
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Obj-C
ray count x sizeof(Ray)
ray count x sizeof(Intersection)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
Where `rayCount` is equal to number of pixels in output image (assuming we are tracing one ray per pixel).
We can make this buffers located comletely in the GPU memory, since we don't need to read or write their contents from the CPU side.

Our last steps would be to write compute shaders for generating rays and handling intersection and dispatch them.
For this first steps demo we will be using orthographic projection. We will generate one ray per pixel, which starts from
`(u, v, -1.0)` and goes in `(0.0, 0.0, 1.0)` direction (remember, our triangle located in the XY plane, with `z = 0`):
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Obj-C
kernel void generateRays(
    device Ray* rays [[buffer(0)]],
    uint2 coordinates [[thread_position_in_grid]],
    uint2 size [[threads_per_grid]])
{
    float2 uv = float2(coordinates) / float2(size - 1);

    uint rayIndex = coordinates.x + coordinates.y * size.x;
    rays[rayIndex].origin = MPSPackedFloat3(uv.x, uv.y, -1.0);
    rays[rayIndex].direction = MPSPackedFloat3(0.0, 0.0, 1.0);
    rays[rayIndex].minDistance = 0.0f;
    rays[rayIndex].maxDistance = 2.0f;
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
After dispatching this compute shader our ray buffer will be filled with rays uniformly distributed in [0..1] coordinates in XY plane.
Then we just need to feed rays buffer to `MPSRayIntersector` and the intersections will be outputted to the separate buffer we created before:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Obj-C
[_rayIntersector encodeIntersectionToCommandBuffer:commandBuffer
                                  intersectionType:MPSIntersectionTypeNearest
                                         rayBuffer:_rayBuffer
                                   rayBufferOffset:0
                                intersectionBuffer:_intersectionBuffer
                          intersectionBufferOffset:0
                                          rayCount:_rayCount
                             accelerationStructure:_accelerationStructure];
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
Here we are asking to find nearest intersection and fill intersection structures with distance, primitive index and
the barycentric coordinates of the hit point, if we actually hit our triangle. Therefore, handling intersection
in our case would be also quite straightforward - if we hit triangle, let'swrite barycentric coordinates,
encoded as color to the output image:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Obj-C
kernel void handleIntersections(
    texture2d<float, access::write> image [[texture(0)]],
    device const Intersection* intersections [[buffer(0)]],
    uint2 coordinates [[thread_position_in_grid]],
    uint2 size [[threads_per_grid]])
{
    uint rayIndex = coordinates.x + coordinates.y * size.x;
    device const Intersection& i = intersections[rayIndex];
    if (i.distance > 0.0f)
    {
        float w = 1.0 - i.coordinates.x - i.coordinates.y;
        image.write(float4(i.coordinates, w, 1.0), coordinates);
    }
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

And if everything went well, we will see a colored triangle over our test image:
![](images/pic-3.png)

**That’s it!**

In the [next post](../part-2/index.html) we will load and trace geometry from a file,
prepare an environment for path tracing, and implement simple diffuse BRDF with next event estimation

[Return to the index](../index.html)

Support
=======================================================
<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
  <input type="hidden" name="cmd" value="_s-xclick" />
  <input type="hidden" name="hosted_button_id" value="2BYWG6QUS8VSJ" />
  <input type="image" src="https://www.paypalobjects.com/en_US/DK/i/btn/btn_donateCC_LG.gif" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" />
  <img alt="" border="0" src="https://www.paypal.com/en_DE/i/scr/pixel.gif" width="1" height="1" />
</form>

<!-- Markdeep: -->
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js"></script>
<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
