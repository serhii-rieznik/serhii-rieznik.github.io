<meta charset="utf-8">
**Going slightly physically based**

In the previous parts we've implemented diffuse and rough conductor materials. 
Now we going to add two materials - plastic and dielectric. Also, we are going to
make sure that our materials are physically correct (or at least plausible).

[Source Code](http://github.com/sergeyreznik/metal-ray-tracer/tree/part-4)
for this post is available on my GitHub page. Additionally, I've created a 
[repository](https://github.com/sergeyreznik/raytracing-references) with scenes that were used to 
validate ray-tracer.

![Scene from Pica Pica](images/pic-0.png)

**A small note:**

I will use a term "BSDF" (bidirectional scattering distribution function) rather than "BRDF" (bidirectional reflection distribution function) 
because it is more general and describes not only reflections, but also transmittance and diffuse scattering.

Easy way to validate results
================================================================================
Before implementing new materials, we need to figure out a way to make sure that our materials are
physically correct. In the previous posts I compared images produced by ray-tracer with those produced by Mitsuba. 
But such comparison gives nothing but visual similarity, and while rendering could be 
incorrect it will still be visually similar to the correct one. Therefore, if we want to compare images against Mitsuba
we need to develop a more robust way to do it. 

I propose a simple method, that will be able to quickly provide an information about luminance
in the images, and compare it to the reference image produced by Mitsuba (or PBRT if you want). Take a look at these two images:

![](images/pic-1.png)![](images/pic-2.png)

They look almost identical and what is important they both looks natural. It is hard to notice that the glass box is
slightly different (I intentionally modified Fresnel term), especially when comparing final image to the reference. 

So let's make a simple comparison method: get the average value from red, green and blue components of
 each pixel of source image and reference and find the difference between two averaged values. If the difference is greater than zero
 - it means that image produced by our ray-tracer is brighter than the reference and vice versa. So, let's output this
 difference to the green channel if is greater than zero and negative difference to the red channel if it is smaller than zero:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
float colorLum = dot(color.xyz, 1.0f / 3.0f);
float referenceLum = dot(referenceColor.xyz, 1.0f / 3.0f);
float diff = (colorLum - referenceLum) * COMPARE_SCALE;
color = (diff > 0.0f) ? 
    float4(0.0f, diff, 0.0f, 1.0f) :
    float4(-diff, 0.0f, 0.0f, 1.0f);
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Obviously, in this situation colors like (1, 0, 0) and (0, 0, 1) would look the same, but we are trying to compare brightness of 
the pixel, but not it's color. Also that's why I decided to compare average values, rather than color converted to grayscale. 
Comparing colors converted to grayscale is more proper method, but difference in blue colors (for example) would be much noticable than in green.

Ideally we would see a black color if we matched the reference perfectly. But in the real world there a several factors 
that won't allow us to see a perfect zero difference:
- number of samples are usually limited, which leads to noise;
- .exr format (to which Mitsuba and PBRT can save results) stores data as half floats (16 bits), which introduces rounding errors.

This mean that even when we implemented everything correctly we will likely be seeing a red-green noise on the image. 

Compare the difference images below. These are difference between images above and the reference image:

![](images/pic-3.png)![](images/pic-4.png)

Note the glass box: on the first image we can see an almost uniform red-green noise, 
while on the second image glass box has noticeable darker (reddish) sides. 

This is very rough method to estimate a similarity to the reference, but it gives results almost immediately.

Furnace test
================================================================================
Another (and actually more proper) way to validate materials is so called "Furnace test". The name comes from a property of a furnace in thermal equilibrium. 
When a furnace reaches equilibrium, its interior has a completely uniform appearance, causing all geometric features to disappear [^](http://www.scratchapixel.com/lessons/3d-basic-rendering/global-illumination-path-tracing/global-illumination-path-tracing-practical-implementation).
The idea behind it is to put a white object, (which does not absorb light) usually a sphere, to the environment having uniform color.
If BSDF is implemented correctly (i.e. have energy conservation property) then the object will have the color of the environment -
it will not absorb light and will not emit any additional light. Usually it is good idea to make a gray environment,
in this way it would be easier to notice energy gain.

Take a look on these three images:

![](images/pic-5.png)![](images/pic-6.png)![](images/pic-7.png)

The first one - is the correct plastic BSDF implementation. In the second one BSDF was not multiplied by cosine between normal and outgoing ray direction,
the third one does not account for Fresnel in diffuse component and probability distribution function.

So now we have a least two methods to verify our BSDFs, so let's implement plastic and dielectric materials. But before
I want to slightly refactor shader code to eliminate all duplications, let's keep two methods:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
inline SampledMaterial evaluateMaterial(device const Material& material,
    float3 nO, float3 wI, float3 wO)
{
    // evaluate values such as BSDF, PDF and weight
    ...
}


SampledMaterial sampleMaterial(device const Material& material,
    float3 nO, float3 wI, device const RandomSample& randomSample)
{
    // sample outgoing direction and then call evaluateMaterial
    // with the corresponding wO
    ...
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

We will be using `sampleMaterial` (which will call `evaluateMaterial` inside) for generating new ray direction and
`evaluateMaterial` for the next event estimation. All code related to BSDF evaluation will only be located in the
`evaluateMaterial` method.


Plastic BSDF
================================================================================
Plastic material consists of two components - specular and diffuse. It reflects portion of light (specular component)
and absorbs and then re-emits rest of the light (diffuse component). The exact amount of reflected light is defined by
Fresnel equations, I believe they are pretty common in computer graphics and I don't need to go in details with them.
Usually, Schlik approximation is being used, but since we are going slightly physically based, let's use real formula.

Considering unpolarized light, a function which calculates Fresnel equation will look like:
<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
inline float fresnelDielectric(float3 i, float3 m, float eta)
{
    float result = 1.0f;
    float cosThetaI = abs(dot(i, m));
    float sinThetaOSquared = (eta * eta) * (1.0f - cosThetaI * cosThetaI);
    if (sinThetaOSquared <= 1.0)
    {
        float cosThetaO = sqrt(saturate(1.0f - sinThetaOSquared));
        float Rs = (cosThetaI - eta * cosThetaO) / (cosThetaI + eta * cosThetaO);
        float Rp = (eta * cosThetaI - cosThetaO) / (eta * cosThetaI + cosThetaO);
        result = 0.5f * (Rs * Rs + Rp * Rp);
    }
    return result;
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
*(read more on [Fresnel reflectance](http://www.pbr-book.org/3ed-2018/Reflection_Models/Specular_Reflection_and_Transmission.html#FresnelReflectance) in PBRT)*

Where `eta` is ratio of index of refractions - IOR of medium from light arrives divided by IOR of
medium to which light is being transmitted. For plastic it is common case to use 1.5 as IOR, but we want this to be
customizable.

In order to sample plastic material, we need to decide if this would be reflected or diffuse ray. We can use Fresnel
equations here as well, and say that probability of generating reflected ray is equal to the value of Fresnel:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
inline SampledMaterial sample(device const Material& material,
    float3 nO, float3 wI, device const RandomSample& randomSample)
{
    // sample microfacet at given point
    float alphaSquared = material.roughness * material.roughness;
    float3 m = sampleGGXDistribution(nO, randomSample.bsdfSample, alphaSquared);

    // calculate Fresnel equation for given microfacet
    float F = fresnelDielectric(wI, m, material.extIOR, material.intIOR);

    float3 wO = {};
    if (randomSample.componentSample < F)
    {
        wO = reflect(wI, m);
    }
    else
    {
        wO = sampleCosineWeightedHemisphere(nO, randomSample.bsdfSample);
    }

    return evaluate(material, nO, wI, wO);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

**It is important to not forget to plug Fresnel value into the PDF.**

Therefore, we are generating either reflected ray or uniformly (actually cosine-weighted) ray around geometric normal.

Now we need a function that evaluates plastic material. We will be using the same microfacet BSDF which we used for
conductors in the previous part, but now instead of `fresnelConductor` we will be using `fresnelDielectric` method.
As we mentioned before - part of the light will be reflected (specular component) - this part is defined by microfacet
material, and diffuse part is defined by the same diffuse BSDF but scaled with `(1.0f - F)`, which means that diffuse light
is all light which was not reflected.

Since we used Fresnel term as a probability for generating reflected ray we need to plug it into the
probability density function. PDF of plastic material also consists of PDF of microfacet BSDF scaled by probability of
generating reflected ray (`F`) and PDF of diffuse BSDF, scaled by probability of generating diffuse ray (`1.0f - F`).
Since we can't nicely cancel components of `bsdf / pdf` as we did with conductor material - we will write weight
just as a ratio between BSDF and PDF:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
SampledMaterial result;
// ...
float3 m = normalize(wO - wI);
float NdotM = dot(nO, m);
float MdotO = dot(m, wO);

float a = material.roughness * material.roughness;
float F = fresnelDielectric(wI, m, material.extIOR, material.intIOR);
float D = ggxNormalDistribution(a, nO, m);
float G = ggxVisibilityTerm(a, wI, wO, nO, m);
float J = 1.0f / (4.0 * MdotO);

result.bsdf =
    material.diffuse * INVERSE_PI * NdotO * (1.0f - F) +
    material.specular * (F * D * G / (4.0 * NdotI));

result.pdf =
    INVERSE_PI * NdotO * (1.0f - F) +
    D * NdotM * J * F;

result.weight = result.bsdf / result.pdf;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

This will give use nice plastic spheres:

![Actually every surface on this image is plastic, just with various roughness](images/pic-8.png)

Glass BSDF
================================================================================
*(glass BSDF is based on a [classic paper](https://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.pdf) :
**Microfacet Models for Refraction through Rough Surfaces**)*

Glass material also consists of two components - specular and transmittance. Specular is pretty much the same as in plastic
material, while transmittance is a little bit tricky. So, I will mostly focus on transmittance.

We going to use same approach for sampling glass material - use Fresnel term as a probability of generating reflected ray and
`(1.0f - F)` as a probability of generating transmitted ray.

Notice the condition in the method that calculates Fresnel equation:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
...
if (sinThetaOSquared <= 1.0)
...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Using Snell's law:

\( \eta_i * sin\theta_i = \eta_o * sin\theta_o \)

we can figure out a critical angle, where \(sin\theta_o\) would be greater than one, and which will mean a
[total internal reflection](https://en.wikipedia.org/wiki/Total_internal_reflection). In this case Fresnel term will
return `1.0f` and therefore we always will be generating reflected ray, so we don't need to add any extra conditions to our code.

Now let's get to the implementation of sampling method itself.

At first, we should remember that there are two cases for the transmitted ray. One when ray enters denser medium and
the second when rays goes from denser medium:

![](images/d-1.png) ![](images/d-2.png)

The difference is that in the second case we need to flip a normal, in order to make our computation consistent,
considering \((\omega_i • n) < 0.0 \). Also, we need to use proper indices of refraction for incoming and outgoing rays:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
inline SampledMaterial sample(device const Material& material,
    float3 nO, float3 wI, device const RandomSample& randomSample)
{
    bool enteringMaterial = dot(nO, wI) < 0.0f;
    float3 n = enteringMaterial ? nO : -nO;
    float etaI = enteringMaterial ? material.extIOR : material.intIOR;
    float etaO = enteringMaterial ? material.intIOR : material.extIOR;
    float eta = etaI / etaO;
    ...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Now we can sample a microfacet around correctly oriented normal, compute Fresnel term and select either reflected or refracted ray:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
    ...
    float a = remapRoughness(material.roughness, dot(n, wI));
    float3 m = sampleGGXDistribution(n, randomSample.bsdfSample, a);

    float F = fresnelDielectric(wI, m, eta);

    float3 wO = { };
    if (randomSample.componentSample > F)
    {
        float cosThetaI = dot(m, -wI);
        float sinThetaOSquared = (eta * eta) * (1.0f - cosThetaI * cosThetaI);
        float cosThetaO = sqrt(saturate(1.0f - sinThetaOSquared));

        wO = normalize(eta * wI + m * (eta * cosThetaI - cosThetaO));

        if (dot(n, wI) * dot(n, wO) <= 0.0f) return {};
    }
    else
    {
        wO = reflect(wI, m);
        if (dot(n, wO) * dot(n, wI) >= 0.0f) return {};
    }

    return evaluate(material, nO, wI, wO);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
*(please refer to the [original paper](https://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.pdf) for the derivation and details, 
section 5.3 - Sampling and weights, Eq. 39, 40)*

**It is important** to pass original (not flipped normal) into the `evaluate` method, since it could be used separately and also does the same check.

Evaluation method would be a little trickier. Before evaluating we have to determine not only if ray enters material
(exactly in the same way as we did in sampling method):

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
inline SampledMaterial evaluate(device const Material& material,
float3 nO, float3 wI, float3 wO)
{
    bool enteringMaterial = dot(nO, wI) < 0.0f;
    float3 n = enteringMaterial ? nO : -nO;
    float eta = enteringMaterial ?
        (material.extIOR / material.intIOR) : (material.intIOR / material.extIOR);
    ...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

But we also need to determine if given incoming and outgoing rays (\(\omega_i\) and \(\omega_o\)) describes reflection,
or refraction event. We can do that by checking if both vectors lies in the same hemisphere. If they are - this is reflection,
if \(\omega_o\) lies in the other hemisphere than \(\omega_i\) - it mean that the ray was refracted into the material:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
    ...
    float NdotI = -dot(n, wI);
    float NdotO = dot(n, wO);
    bool reflection = NdotO * NdotI > 0.0f;
    ...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Now we need to determine a half-vector, or microfacet. For the reflection it would just normalized sum of incoming and
outgoing vectors (but since we considering \((\omega_i • n) < 0.0\), we should take incoming direction with negative sign):

![](images/d-3.png)

But for the refraction, the half vector is computed slightly differently. In general case it would be:

\(m = -(\omega_i * \eta + \omega_o)\)

But since we have \(\omega_i\) flipped, we can rewrite this as:

\(m = \omega_i * \eta - \omega_o\)

![](images/d-4.png)

Also, if we flipped a normal, we need to make sure that normal and microfacet both lies in the same hemisphere:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
    ...
    float3 m = normalize(reflection ? (wO - wI) : (wI * eta - wO));
    m *= (dot(n, m) < 0.0f) ? -1.0f : 1.0f;
    ...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Now, everything is ready and if ray was reflected we can calculate specular BSDF, pretty much as we did with plastic.
But if ray is transmitted we will use another values for BSDF *(again please refer to the
[original paper](https://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.pdf) for the derivation and details, sections 4 and 5)*:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
    ...
    float MdotI = -dot(m, wI);
    float MdotO = dot(m, wO);
    float NdotM = dot(n, m);
    float alpha = remapRoughness(material.roughness, NdotI);

    float F = fresnelDielectric(wI, m, eta);
    float D = ggxNormalDistribution(alpha, n, m);
    float G = ggxVisibilityTerm(alpha, wI, wO, n, m);

    if (reflection)
    {
        float J = 1.0f / (4.0f * MdotO);

        result.bsdf = material.specular * (D * G * F / (4.0f * NdotI));
        result.pdf = F * J;
        result.weight = material.specular;
        result.eta = 1.0f;
    }
    else
    {
        float J = MdotI / sqr(MdotI * eta + MdotO);

        float value = (1.0f - F) * D * G * MdotI * MdotO /
            (NdotI * sqr(MdotI * eta + MdotO));

        result.bsdf = material.transmittance * abs(value);
        result.pdf = (1.0f - F) * J;

        result.weight = material.transmittance;
        result.eta = eta;
    }

    result.pdf *= D * NdotM;
    result.weight *= abs(G * MdotI / (NdotI * NdotM));
    result.valid = uint(dot(result.bsdf, result.bsdf) > 0.0f) *
        uint(result.pdf > 0.0f);

    return result;
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
*(notice that we have an extra parameter in our `SampledMaterial` structure, named `eta`, it is required for the
Russian roulette, which will be described below)*

If we did everything correctly - it will give us nice glass spheres:

![](images/pic-9.png)

Unbiased rendering
================================================================================
Before this part we had a custom number of bounces per pixel each frame. But this introduces bias to our rendering,
since not all bounces are taken into the account. If we want to be physically based we have to calculate infinite
amount of bounces, but how can we do that?

At first we need to refactor our rendering code. Before this part it was like (in very rough pseudocode):

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
void render()
{
    generateRays();
    for (int i = 0; i < bounces; ++i)
    {
        bounce();
    }
    accumulate();
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

But now, let's distribute not samples, but **bounces** in time:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
void render()
{
    generateRaysIfRequired();
    bounce();
    accumulateCompletedRays();
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

Each ray will have a property, describing if the ray has finished his path. We will be only generating new rays if
current one is completed and accumulate image only using completed rays. Like:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
kernel void generateRays(
    device Ray* rays [[buffer(0)]],
    device const RandomSample* noise [[buffer(1)]],
    constant ApplicationData& appData [[buffer(2)]],
    uint2 coordinates [[thread_position_in_grid]],
    uint2 size [[threads_per_grid]])
{
    uint rayIndex = coordinates.x + coordinates.y * size.x;
    device Ray& r = rays[rayIndex];
    if ((appData.frameIndex == 0) || (r.completed != 0))
    {
        // generate a new ray
        ...
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

and

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
kernel void accumulateImage(
    texture2d<float, access::read_write> image [[texture(0)]],
    device const Ray* rays [[buffer(0)]],
    constant ApplicationData& appData [[buffer(1)]],
    uint2 coordinates [[thread_position_in_grid]],
    uint2 size [[threads_per_grid]])
{
    uint rayIndex = coordinates.x + coordinates.y * size.x;
    device const Ray& currentRay = rays[rayIndex];
    if (currentRay.completed && (currentRay.generation < MAX_SAMPLES))
    {
        // accumulate image
        ...
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>

This will give us potentially an infinite number of bounces for each ray. And a ray will be completed only if it goes
out of scene and hits background. But imagine a scene, which is completely surrounded by geometry and there is no change
for ray to escape it. I've added such scene to my [ray-tracing references repository](https://github.com/sergeyreznik/raytracing-references),
in this scene camera is located inside glowing sphere, and no ray could escape it. We need to make sure such scenes
will also be handled properly. Luckily for us, there is one method than not only makes this possible, but is commonly used for
improving efficiency of the Monte-Carlo estimator.

This method is called Russian roulette. The idea behind it to discard paths that are expensive to calculate, but does not contribute
(at least significantly) to the final image. This could be done by chosing a probability of terminating ray, based on ray's
throughput. And then either terminate ray or scale ray's throughput by inverse probability of continuing path, which will account all terminated paths:

<script type="preformatted">
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Obj-C
if (currentRay.bounces >= 5)
{
    float q = min(0.95f, max(currentRay.throughput.x,
        max(currentRay.throughput.y, currentRay.throughput.z)));

    if (randomSample.rrSample < q)
    {
        currentRay.throughput *= 1.0f / q;
    }
    else
    {
        currentRay.completed = 1;
    }
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</script>
*(read more about Russian roulette [here](http://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/Russian_Roulette_and_Splitting.html))*

In this way we can say that we are calculating potentialy infinite amount of samples, and this is a step to a physically-correct and unbiased rendering.

**That’s it!**

[Return to the index](../index.html)

Support
=======================================================
<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
  <input type="hidden" name="cmd" value="_s-xclick" />
  <input type="hidden" name="hosted_button_id" value="2BYWG6QUS8VSJ" />
  <input type="image" src="https://www.paypalobjects.com/en_US/DK/i/btn/btn_donateCC_LG.gif" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" />
  <img alt="" border="0" src="https://www.paypal.com/en_DE/i/scr/pixel.gif" width="1" height="1" />
</form>

<!-- Markdeep: -->
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js"></script>
<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
